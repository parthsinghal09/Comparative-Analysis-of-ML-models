{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset_comb.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity',\n",
       "       'ConvexArea', 'EquivDiameter', 'Extent', 'Perimeter', 'Roundness',\n",
       "       'AspectRation', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12250</th>\n",
       "      <td>9438</td>\n",
       "      <td>161.083574</td>\n",
       "      <td>75.264812</td>\n",
       "      <td>0.884130</td>\n",
       "      <td>9668</td>\n",
       "      <td>109.621325</td>\n",
       "      <td>0.690973</td>\n",
       "      <td>386.763</td>\n",
       "      <td>0.792866</td>\n",
       "      <td>2.140224</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>5650</td>\n",
       "      <td>153.044539</td>\n",
       "      <td>47.512411</td>\n",
       "      <td>0.950590</td>\n",
       "      <td>5788</td>\n",
       "      <td>84.816292</td>\n",
       "      <td>0.674305</td>\n",
       "      <td>333.668</td>\n",
       "      <td>0.637719</td>\n",
       "      <td>3.221149</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17583</th>\n",
       "      <td>8852</td>\n",
       "      <td>164.424917</td>\n",
       "      <td>69.285681</td>\n",
       "      <td>0.906883</td>\n",
       "      <td>9025</td>\n",
       "      <td>106.163630</td>\n",
       "      <td>0.590133</td>\n",
       "      <td>382.283</td>\n",
       "      <td>0.761169</td>\n",
       "      <td>2.373144</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>6019</td>\n",
       "      <td>145.911839</td>\n",
       "      <td>53.410877</td>\n",
       "      <td>0.930596</td>\n",
       "      <td>6170</td>\n",
       "      <td>87.542155</td>\n",
       "      <td>0.507675</td>\n",
       "      <td>333.360</td>\n",
       "      <td>0.680624</td>\n",
       "      <td>2.731875</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>6331</td>\n",
       "      <td>148.318323</td>\n",
       "      <td>55.921753</td>\n",
       "      <td>0.926197</td>\n",
       "      <td>6539</td>\n",
       "      <td>89.782401</td>\n",
       "      <td>0.615078</td>\n",
       "      <td>341.567</td>\n",
       "      <td>0.681915</td>\n",
       "      <td>2.652247</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11762</th>\n",
       "      <td>8679</td>\n",
       "      <td>154.317783</td>\n",
       "      <td>72.818877</td>\n",
       "      <td>0.881665</td>\n",
       "      <td>9002</td>\n",
       "      <td>105.121102</td>\n",
       "      <td>0.700315</td>\n",
       "      <td>376.119</td>\n",
       "      <td>0.770955</td>\n",
       "      <td>2.119200</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>8698</td>\n",
       "      <td>155.109378</td>\n",
       "      <td>72.581012</td>\n",
       "      <td>0.883763</td>\n",
       "      <td>8957</td>\n",
       "      <td>105.236104</td>\n",
       "      <td>0.576790</td>\n",
       "      <td>378.111</td>\n",
       "      <td>0.764523</td>\n",
       "      <td>2.137052</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>6114</td>\n",
       "      <td>162.017752</td>\n",
       "      <td>48.565934</td>\n",
       "      <td>0.954016</td>\n",
       "      <td>6243</td>\n",
       "      <td>88.230304</td>\n",
       "      <td>0.794748</td>\n",
       "      <td>350.646</td>\n",
       "      <td>0.624881</td>\n",
       "      <td>3.336037</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>6654</td>\n",
       "      <td>164.277226</td>\n",
       "      <td>52.537835</td>\n",
       "      <td>0.947481</td>\n",
       "      <td>6825</td>\n",
       "      <td>92.044206</td>\n",
       "      <td>0.800433</td>\n",
       "      <td>362.687</td>\n",
       "      <td>0.635666</td>\n",
       "      <td>3.126837</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11768</th>\n",
       "      <td>9485</td>\n",
       "      <td>160.819781</td>\n",
       "      <td>75.882302</td>\n",
       "      <td>0.881681</td>\n",
       "      <td>9731</td>\n",
       "      <td>109.893936</td>\n",
       "      <td>0.596391</td>\n",
       "      <td>389.651</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>2.119332</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "12250  9438       161.083574        75.264812      0.884130        9668   \n",
       "9281   5650       153.044539        47.512411      0.950590        5788   \n",
       "17583  8852       164.424917        69.285681      0.906883        9025   \n",
       "2021   6019       145.911839        53.410877      0.930596        6170   \n",
       "1248   6331       148.318323        55.921753      0.926197        6539   \n",
       "...     ...              ...              ...           ...         ...   \n",
       "11762  8679       154.317783        72.818877      0.881665        9002   \n",
       "12172  8698       155.109378        72.581012      0.883763        8957   \n",
       "10126  6114       162.017752        48.565934      0.954016        6243   \n",
       "8208   6654       164.277226        52.537835      0.947481        6825   \n",
       "11768  9485       160.819781        75.882302      0.881681        9731   \n",
       "\n",
       "       EquivDiameter    Extent  Perimeter  Roundness  AspectRation    Class  \n",
       "12250     109.621325  0.690973    386.763   0.792866      2.140224    Gonen  \n",
       "9281       84.816292  0.674305    333.668   0.637719      3.221149  jasmine  \n",
       "17583     106.163630  0.590133    382.283   0.761169      2.373144    Gonen  \n",
       "2021       87.542155  0.507675    333.360   0.680624      2.731875  jasmine  \n",
       "1248       89.782401  0.615078    341.567   0.681915      2.652247  jasmine  \n",
       "...              ...       ...        ...        ...           ...      ...  \n",
       "11762     105.121102  0.700315    376.119   0.770955      2.119200    Gonen  \n",
       "12172     105.236104  0.576790    378.111   0.764523      2.137052    Gonen  \n",
       "10126      88.230304  0.794748    350.646   0.624881      3.336037  jasmine  \n",
       "8208       92.044206  0.800433    362.687   0.635666      3.126837  jasmine  \n",
       "11768     109.893936  0.596391    389.651   0.785047      2.119332    Gonen  \n",
       "\n",
       "[18185 rows x 11 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max normalisation\n",
    "#0 - jasmine & 1 - Gonen\n",
    "\n",
    "for column in df.columns:\n",
    "    if column!='Class':\n",
    "        maxx = df[column].max()\n",
    "        minn = df[column].min()\n",
    "        for e in df[column]:\n",
    "            e1 = (maxx - e)/(maxx - minn)\n",
    "            df[column] = df[column].replace(e, e1)\n",
    "    elif column == 'Class':\n",
    "        for e in df[column]:\n",
    "            if e == 'jasmine':\n",
    "                df[column] = df[column].replace(e, 0)\n",
    "            elif e == 'Gonen':\n",
    "                df[column] = df[column].replace(e, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12250</th>\n",
       "      <td>0.100416</td>\n",
       "      <td>0.202862</td>\n",
       "      <td>0.151346</td>\n",
       "      <td>0.284853</td>\n",
       "      <td>0.158975</td>\n",
       "      <td>0.076639</td>\n",
       "      <td>0.388609</td>\n",
       "      <td>0.390849</td>\n",
       "      <td>0.153230</td>\n",
       "      <td>0.693742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>0.593132</td>\n",
       "      <td>0.276562</td>\n",
       "      <td>0.727830</td>\n",
       "      <td>0.055780</td>\n",
       "      <td>0.619291</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.421725</td>\n",
       "      <td>0.561301</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.270467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17583</th>\n",
       "      <td>0.176639</td>\n",
       "      <td>0.172230</td>\n",
       "      <td>0.275547</td>\n",
       "      <td>0.206428</td>\n",
       "      <td>0.235259</td>\n",
       "      <td>1.954014</td>\n",
       "      <td>0.588952</td>\n",
       "      <td>0.405232</td>\n",
       "      <td>0.196641</td>\n",
       "      <td>0.602534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.545135</td>\n",
       "      <td>0.341952</td>\n",
       "      <td>0.605305</td>\n",
       "      <td>0.124698</td>\n",
       "      <td>0.573971</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.752776</td>\n",
       "      <td>0.562290</td>\n",
       "      <td>0.306953</td>\n",
       "      <td>0.462060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>0.504553</td>\n",
       "      <td>0.319890</td>\n",
       "      <td>0.553148</td>\n",
       "      <td>0.139857</td>\n",
       "      <td>0.530193</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.539393</td>\n",
       "      <td>1.630759</td>\n",
       "      <td>0.305185</td>\n",
       "      <td>0.493241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11762</th>\n",
       "      <td>0.199142</td>\n",
       "      <td>0.264889</td>\n",
       "      <td>0.202154</td>\n",
       "      <td>0.293351</td>\n",
       "      <td>0.237988</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.370049</td>\n",
       "      <td>0.425020</td>\n",
       "      <td>0.183239</td>\n",
       "      <td>0.701975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>0.196670</td>\n",
       "      <td>0.257632</td>\n",
       "      <td>0.207095</td>\n",
       "      <td>0.286118</td>\n",
       "      <td>0.243327</td>\n",
       "      <td>1.954024</td>\n",
       "      <td>0.615461</td>\n",
       "      <td>0.418625</td>\n",
       "      <td>0.192048</td>\n",
       "      <td>0.694984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>0.532778</td>\n",
       "      <td>0.194298</td>\n",
       "      <td>0.705945</td>\n",
       "      <td>0.043974</td>\n",
       "      <td>0.565310</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.182433</td>\n",
       "      <td>0.506796</td>\n",
       "      <td>0.383296</td>\n",
       "      <td>0.225478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>0.462539</td>\n",
       "      <td>0.173584</td>\n",
       "      <td>0.623440</td>\n",
       "      <td>0.066497</td>\n",
       "      <td>0.496263</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.171139</td>\n",
       "      <td>1.630977</td>\n",
       "      <td>0.368527</td>\n",
       "      <td>0.307398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11768</th>\n",
       "      <td>0.094303</td>\n",
       "      <td>0.205281</td>\n",
       "      <td>0.138520</td>\n",
       "      <td>0.293297</td>\n",
       "      <td>0.151501</td>\n",
       "      <td>1.953442</td>\n",
       "      <td>0.576520</td>\n",
       "      <td>0.381578</td>\n",
       "      <td>0.163939</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "12250  0.100416         0.202862         0.151346      0.284853    0.158975   \n",
       "9281   0.593132         0.276562         0.727830      0.055780    0.619291   \n",
       "17583  0.176639         0.172230         0.275547      0.206428    0.235259   \n",
       "2021   0.545135         0.341952         0.605305      0.124698    0.573971   \n",
       "1248   0.504553         0.319890         0.553148      0.139857    0.530193   \n",
       "...         ...              ...              ...           ...         ...   \n",
       "11762  0.199142         0.264889         0.202154      0.293351    0.237988   \n",
       "12172  0.196670         0.257632         0.207095      0.286118    0.243327   \n",
       "10126  0.532778         0.194298         0.705945      0.043974    0.565310   \n",
       "8208   0.462539         0.173584         0.623440      0.066497    0.496263   \n",
       "11768  0.094303         0.205281         0.138520      0.293297    0.151501   \n",
       "\n",
       "       EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "12250       0.076639  0.388609   0.390849   0.153230      0.693742      1  \n",
       "9281        1.954015  0.421725   0.561301   0.365715      0.270467      0  \n",
       "17583       1.954014  0.588952   0.405232   0.196641      0.602534      1  \n",
       "2021        1.954015  0.752776   0.562290   0.306953      0.462060      0  \n",
       "1248        1.954015  0.539393   1.630759   0.305185      0.493241      0  \n",
       "...              ...       ...        ...        ...           ...    ...  \n",
       "11762       1.954015  0.370049   0.425020   0.183239      0.701975      1  \n",
       "12172       1.954024  0.615461   0.418625   0.192048      0.694984      1  \n",
       "10126       1.954015  0.182433   0.506796   0.383296      0.225478      0  \n",
       "8208        1.954015  0.171139   1.630977   0.368527      0.307398      0  \n",
       "11768       1.953442  0.576520   0.381578   0.163939      0.701923      1  \n",
       "\n",
       "[18185 rows x 11 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 11)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g = np.array_split(data, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracy_log_test = []\n",
    "accuracy_log_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    clf = LogisticRegression(random_state = 0)\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    test_pred_y_log = clf.predict(test_data_xn)\n",
    "    train_pred_y_log = clf.predict(train_data_xn)\n",
    "    \n",
    "    acc1_log = accuracy_score(test_data_yn, test_pred_y_log)\n",
    "    accuracy_log_test.append(acc1_log)\n",
    "    \n",
    "    acc2_log = accuracy_score(train_data_yn, train_pred_y_log)\n",
    "    accuracy_log_train.append(acc2_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9869672986379864\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_log_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for train set =  0.9869397846070092\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_log_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lp_test = []\n",
    "accuracy_lp_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    clf = Perceptron(tol = 1e-3, random_state=0)\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    test_pred_y_lp = clf.predict(test_data_xn)\n",
    "    train_pred_y_lp = clf.predict(train_data_xn)\n",
    "    \n",
    "    acc1_lp = accuracy_score(test_data_yn, test_pred_y_lp)\n",
    "    accuracy_lp_test.append(acc1_lp)\n",
    "    \n",
    "    acc2_lp = accuracy_score(train_data_yn, train_pred_y_lp)\n",
    "    accuracy_lp_train.append(acc2_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9762997310002605\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_lp_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for train set =  0.9764640136062048\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_lp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\titan\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_test = []\n",
    "accuracy_svm_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    clf = SVC(kernel = 'rbf')\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    test_pred_y_svm = clf.predict(test_data_xn)\n",
    "    train_pred_y_svm = clf.predict(train_data_xn)\n",
    "    \n",
    "    acc1_svm = accuracy_score(test_data_yn, test_pred_y_svm)\n",
    "    accuracy_svm_test.append(acc1_svm)\n",
    "    \n",
    "    acc2_svm = accuracy_score(train_data_yn, train_pred_y_svm)\n",
    "    accuracy_svm_train.append(acc2_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9872971804086138\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_svm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for train set =  0.9874621915058807\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_svm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_nb_test = []\n",
    "accuracy_nb_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    test_pred_y_nb = clf.predict(test_data_xn)\n",
    "    train_pred_y_nb = clf.predict(train_data_xn)\n",
    "    \n",
    "    acc1_nb = accuracy_score(test_data_yn, test_pred_y_nb)\n",
    "    accuracy_nb_test.append(acc1_nb)\n",
    "    \n",
    "    acc2_nb = accuracy_score(train_data_yn, train_pred_y_nb)\n",
    "    accuracy_nb_train.append(acc2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9844377321902908\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_nb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for train set =  0.9846393545198554\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_nb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher Linear Discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_fl_test = []\n",
    "accuracy_fl_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    test_pred_y_fl = clf.predict(test_data_xn)\n",
    "    train_pred_y_fl = clf.predict(train_data_xn)\n",
    "    \n",
    "    acc1_fl = accuracy_score(test_data_yn, test_pred_y_fl)\n",
    "    accuracy_fl_test.append(acc1_fl)\n",
    "    \n",
    "    acc2_fl = accuracy_score(train_data_yn, train_pred_y_fl)\n",
    "    accuracy_fl_train.append(acc2_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9840527783731036\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_fl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for train set =  0.9841077812982807\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_fl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ann_test = []\n",
    "accuracy_ann_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    clf = MLPClassifier(hidden_layer_sizes = (10, 10, 10, 10,), max_iter = 1000, activation = 'logistic', solver = 'adam', \n",
    "                        random_state = 1)\n",
    "    \n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    test_pred_y_ann = clf.predict(test_data_xn)\n",
    "    train_pred_y_ann = clf.predict(train_data_xn)\n",
    "    \n",
    "    acc1_ann = accuracy_score(test_data_yn, test_pred_y_ann)\n",
    "    accuracy_ann_test.append(acc1_ann)\n",
    "    \n",
    "    acc2_ann = accuracy_score(train_data_yn, train_pred_y_ann)\n",
    "    accuracy_ann_train.append(acc2_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.987792087758206\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_ann_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for train set =  0.9876821550285966\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_ann_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.boxplot([accuracy_log_test, accuracy_lp_test, accuracy_svm_test, accuracy_nb_test, accuracy_fl_test, accuracy_ann_test])\n",
    "\n",
    "plt.text(0.75, 0.98, \"Logistic Regression\")\n",
    "plt.text(0.80, statistics.mean(accuracy_log_test) + 0.0006, \"Mean: \" + str(round(statistics.mean(accuracy_log_test), 5)))\n",
    "\n",
    "plt.text(1.75, 0.99, \"Linear Perceptron\")\n",
    "plt.text(1.82, statistics.mean(accuracy_lp_test) + 0.0001, \"Mean: \" + str(round(statistics.mean(accuracy_lp_test), 5)))\n",
    "\n",
    "plt.text(2.70, 0.98, \"Support Vector Machine\")\n",
    "plt.text(2.82, statistics.mean(accuracy_svm_test) + 0.0002, \"Mean: \" + str(round(statistics.mean(accuracy_svm_test), 5)))\n",
    "\n",
    "plt.text(3.85, 0.98, \"Naive Bayes\")\n",
    "plt.text(3.80, statistics.mean(accuracy_nb_test) + 0.001, \"Mean: \" + str(round(statistics.mean(accuracy_nb_test), 5)))\n",
    "\n",
    "plt.text(4.68, 0.98, \"Fisher Linear Discriminant\")\n",
    "plt.text(4.80, statistics.mean(accuracy_fl_test) + 0.001, \"Mean: \" + str(round(statistics.mean(accuracy_fl_test), 5)))\n",
    "\n",
    "plt.text(5.68, 0.98, \"Artificial Neural Networks\")\n",
    "plt.text(5.80, statistics.mean(accuracy_ann_test), \"Mean: \" + str(round(statistics.mean(accuracy_ann_test), 5)))\n",
    "\n",
    "#plt.savefig(\"boxPlot.jpeg\")\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
